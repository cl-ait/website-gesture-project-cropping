<!DOCTYPE html>
<html lang="ja">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="title" content="エージェントの発話とジェスチャによる調理動画支援システムの構築 - 肥田京佳, 徳久良子">
  <meta name="description"
    content="調理動画におけるエージェント型支援システム。GPT-4.1による画像切り出しとジェスチャ選択により、視聴者の理解を支援します。120名の評価実験で人間と同等の精度を達成。">
  <meta name="keywords" content="調理動画, エージェント, GPT-4, CLIP, 視覚的注意誘導, AI, マルチモーダル, 画像切り出し, レシピ理解">
  <meta name="author" content="肥田京佳, 徳久良子">
  <meta name="robots" content="index, follow">
  <meta name="language" content="Japanese">

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="愛知工業大学">
  <meta property="og:title" content="エージェントの発話とジェスチャによる調理動画支援システムの構築">
  <meta property="og:description" content="調理動画におけるエージェント型支援システムの提案。">
  <meta property="og:url" content="https://cl-ait.github.io/Website-gesture-project-cropping/">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2025-11-21T12:00:00.000Z">
  <meta property="article:author" content="KyokaHida">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="image-cropping">
  <meta property="article:tag" content="recipe-video">
  <meta property="article:tag" content="multimodal-ai">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="エージェントの発話とジェスチャによる調理動画支援システムの構築">
  <meta name="twitter:description" content="調理動画における視聴者理解を支援するエージェント型インターフェースにおいて， エージェントの説明箇所を自動切り出しする手法を提案">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="エージェントの発話とジェスチャによる調理動画支援システムの構築">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="エージェントの発話とジェスチャによる調理動画支援システムの構築">
  <meta name="citation_author" content="Hida, Kyoka">
  <meta name="citation_author" content="Tokuhisa, Ryoko">
  <meta name="citation_publication_date" content="To appear">
  <meta name="citation_conference_title" content="To appear">
  <meta name="citation_pdf_url" content="To appear">

  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">

  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">

  <title>エージェントの発話とジェスチャによる調理動画支援システムの構築</title>

  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">

  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">

  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>

  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">

  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>

  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "To appear",
    "description": "To appear",
    "author": [
      {
        "@type": "Person",
        "name": "To appear",
        "affiliation": {
          "@type": "Organization",
          "name": "To appear"
        }
      },
      {
        "@type": "Person",
        "name": "To appear",
        "affiliation": {
          "@type": "Organization",
          "name": "To appear"
        },
        {
          "@type": "Organization",
          "name": "To appear"
        }
      }
    ],
    "datePublished": "",
    "publisher": {
      "@type": "Organization",
      "name": "To appear"
    },
    "url": "https://cl-ait.github.io/Website-gesture-project-cropping/",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["To appear"],
    "abstract": "To appear",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://cl-ait.github.io/Website-gesture-project-cropping/"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "To appear"
      }
    ]
  }
  </script>

  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "AICHI INSTITUTE OF TECHNOLOGY",
    "url": "https://aitech.ac.jp/~nlplab/index.html#news"

  }
  </script>
</head>

<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">エージェントの発話とジェスチャによる<br>調理動画支援システムの構築</h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <!-- <a href="FIRST AUTHOR PERSONAL LINK" target="_blank"> -->
                  肥田京佳
                  <!-- </a> -->
                  <sup>1</sup>,</span>
                <span class="author-block">
                  <!-- <a href="SECOND AUTHOR PERSONAL LINK" target="_blank"> -->
                  徳久良子
                  <!-- </a> -->
                  <sup>1,2</sup></span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>愛知工業大学,<sup>2</sup>理化学研究所<br></span>
              </div>

              <div class="columns is-centered">
                <div class="column is-narrow has-text-centered">
                  <button class="button is-normal is-rounded is-dark" disabled title="Paper not yet published">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper (To appear)</span>
                  </button>
                </div>

                <div class="column is-narrow has-text-centered">
                  <a href="https://github.com/cl-ait/image_cropping" target="_blank"
                    class="button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </div>
              </div>

            </div>
          </div>
        </div>
      </div>
      </div>
    </section>
    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">概要</h2>
            <div class="content has-text-justified">
              <p>
                本研究では、調理動画における視聴者理解を支援するエージェント型インターフェースにおいて，
                エージェントの説明箇所を自動切り出しする手法を提案します。
                本手法は、調理場面におけるさまざまな食材や調理器具の位置・状態を言語情報と対応づけて解析し、
                レシピ文中の説明発話（例：「タマネギを微塵切りにします。」）と対応する画像内の領域（食材や調理器具など）を、
                GPT-4.1を用いて抽出した上で、エージェント対話向けに補正する手法です。
                一般の被験者120名による評価実験の結果、提案手法の画像切り出しは、
                人間による画像切り出しと同等の精度であることが分かりました。今後はエージェントの動作生成や、
                調理の学習に対する有効性の検証に取り組む予定です。
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <!-- Problem Statement -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <h2 class="title is-3 has-text-centered">背景と課題</h2>
          <div class="content has-text-justified">
            <h3 class="title is-4">調理動画学習の課題</h3>
            <p>
              調理動画には映像・音声・字幕といった様々な情報が同時に提示されるため、
              調理経験の少ない初心者にとっては以下のような困難があります：
            </p>
            <div class="columns is-multiline" style="margin-top: 1.5rem;">
              <div class="column is-6">
                <div class="box" style="height: 100%; background: #fef3c7;">
                  <h4 class="title is-5">注意の分散</h4>
                  <p>映像・音声・字幕が同時に提示されるため、「どこに注目すべきか」が分かりにくく、注意が分散しやすい</p>
                </div>
              </div>
              <div class="column is-6">
                <div class="box" style="height: 100%; background: #fecaca;">
                  <h4 class="title is-5">視覚的な注意喚起の不足</h4>
                  <p>包丁の扱いや火の使用、油はねなどの危険な場面でも映像が淡々と進行するため、危険性が十分に伝わらず、視聴者が危険箇所を見落とす恐れがある</p>
                </div>
              </div>
            </div>
            <p style="margin-top: 1rem;">
              これらの課題により、視聴者が調理手順を誤って解釈したり、危険箇所を見落とす可能性があり、
              調理に対する理解促進および安全性の観点から改善が求められます。
            </p>
          </div>
        </div>
      </div>
    </section>

    <!-- Solution Approach -->
    <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <h2 class="title is-3 has-text-centered">提案手法：調理動画支援システム</h2>
          <div class="content has-text-justified">
            <p style="font-size: 1.1rem; margin-bottom: 2rem;">
              料理番組のように、エージェントが視聴者に寄り添って<strong>「ここを見てください」</strong>と
              視線を誘導し、<strong>補足説明</strong>や<strong>注意喚起</strong>を行うシステムを目指します。
            </p>

            <div class="columns">
              <div class="column is-6">
                <h3 class="title is-5">視線誘導</h3>
                <p>
                  画像から重要な箇所（食材・調理器具など）を<strong>自動切り出し</strong>し、
                  エージェントが指差しジェスチャで明確に示します。
                </p>
              </div>
              <div class="column is-6">
                <h3 class="title is-5">音声による補足説明</h3>
                <p>
                  「しっかり炒めるとはこういう状態です」「包丁で手を切らないよう注意してください」
                  など、タイミングに応じた説明を提供します。
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Processing Flow -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <h2 class="title is-3 has-text-centered">処理フロー</h2>
          <div class="has-text-centered">
            <div
              style="padding: 2rem; background: white; border-radius: 12px; box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1);">
              <img src="static/images/system_flow.jpg" alt="Overall pipeline and processing flow" loading="lazy"
                style="width: 100%; border-radius: 8px;">
            </div>
            <p class="content has-text-justified" style="margin-top: 1rem; color: #64748b;">
              本研究の調理動画支援システムは、入力画像と説明発話を受け取り、画像切り出し、ジェスチャ選択、配置の3つのモジュールで処理を行います。
              画像切り出しモジュールでは、GPT-4.1 を用いて主要オブジェクト領域を検出・切り出しを行います。
              ジェスチャ選択モジュールでは、補足説明を生成し、CLIP によるテキスト類似度と画像類似度を統合して最適なジェスチャを選択します。
              配置モジュールでは、エージェントの位置と指差し方向を調整し、視聴者が注目すべき箇所を直感的に理解できるようにします。
              これにより、エージェントは「何を」「どこで」「どのように」提示すべきかを推定し、視聴者の注意を効果的に誘導できます。
            </p>
          </div>
        </div>
      </div>
    </section>

    <!-- End mProcessing Flow -->

    <!-- Solution Approach -->
    <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <h2 class="title is-3 has-text-centered">なぜ画像切り出しが必要か？</h2>
          <div class="content has-text-justified">
            <div style="background: white; padding: 1.5rem; border-radius: 8px; margin-top: 2rem;">
              <p>
                エージェントが「ここを見てください」と指差すためには、画像内の<strong>どの領域</strong>に
                注目すべきかを正確に特定する必要があります。本研究では、説明発話（例：「タマネギを微塵切りにします」）
                から、該当する画像領域（タマネギと包丁）を<strong>GPT-4.1を用いて自動抽出</strong>することで、
                エージェントが指差しに必要な情報を得ることを目的としています。
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>


    <!-- Cropping Example -->
    <section class="hero is-small">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <h2 class="title is-3 has-text-centered">切り出し画像例</h2>
          <div class="has-text-centered">
            <div
              style="padding: 2rem; background: white; border-radius: 12px; box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1);">
              <img src="static/images/cropping_example.jpg" alt="Overall pipeline and processing flow" loading="lazy"
                style="width: 100%; border-radius: 8px;">
            </div>
            <p class="content has-text-justified" style="margin-top: 1rem; color: #64748b;">
              提案手法では、調理シーンの画像と説明発話（タマネギを微塵切りにします。）を入力として、
              説明発話と最も関連する画像領域を自動的に抽出し、当該領域を切り出します。
              これにより、レシピの各工程における視覚的な焦点を明確化し、視聴者の理解を支援できます。
            </p>
          </div>
        </div>
      </div>
    </section>

    <!-- Acknowledgments -->
    <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <h2 class="title is-3 has-text-centered">謝辞</h2>
          <div class="content has-text-justified">
            <div style="background: white; padding: 1.5rem; border-radius: 8px; margin-top: 2rem;">
              <p>
                本研究では、国立情報学研究所(NII)の情報学研究データリポジトリ(IDR)より提供されている
                <a href="https://www.nii.ac.jp/dsc/idr/rdata/COM_Kitchens/" target="_blank" rel="noopener noreferrer"><strong>OSX 調理映像データセット(COM-Kitchens)</a></strong>を利用させていただきました。<br>
              </p>
              <p>
                また、エージェントシステムの実装には、<a href="https://mmdagent-ex.dev/ja/" target="_blank" rel="noopener noreferrer"><strong>MMDAgent-EX</strong></a>および<a href="https://github.com/mmdagent-ex/uka" target="_blank" rel="noopener noreferrer"><strong>CGアバター うか</a></strong>を使用させていただきました。
              </p>
              <p style="margin-top: 1rem; font-size: 1em; color: #666;">
                これらの優れたリソースを提供してくださった関係者の皆様に深く感謝いたします。
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>


    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">

              <p>
                This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank">Academic Project Page Template</a> which was adopted from the <a
                  href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
                You are free to borrow the source code of this website, we just ask that you link back to this page in
                the footer. <br> This website is licensed under a <a rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                  Commons Attribution-ShareAlike 4.0 International License</a>.
              </p>

            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>

</html>